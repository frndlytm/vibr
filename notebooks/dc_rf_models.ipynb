{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Decision Tree and Random Forests for Mood Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create class to run binary classification using either model on each of the moods in\n",
    "the label set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiLabelClassify:\n",
    "    '''\n",
    "    Multilabel Classifier for fitting binary classification to each label.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model):\n",
    "        '''\n",
    "        Set up an instance of the classifier.\n",
    "        :param model: Choice of 'RF' for random forest or 'DC' for decision tree\n",
    "        '''\n",
    "        self.fit_models = None\n",
    "        if model != 'RF' and model != 'DC':\n",
    "            raise Exception('Choose RF or DC as model type')\n",
    "        self.model_choice = model\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Fit model with provided features and labels\n",
    "        :param X: features vector\n",
    "        :param y: matching labels, where length of each vector contains all label classifications\n",
    "        for the given features vector\n",
    "        '''\n",
    "        classes = len(y[0])\n",
    "        self.fit_models = []\n",
    "\n",
    "        if len(X) != len(y):\n",
    "            raise Exception(\"Incompatible featues and label lengths\")\n",
    "\n",
    "        for i in range(classes):\n",
    "            if self.model_choice == 'RF':\n",
    "                m_i = RandomForestClassifier(max_features='sqrt', bootstrap=True, n_estimators=100)\n",
    "            else:\n",
    "                m_i = DecisionTreeClassifier()\n",
    "            m_i.fit(X,  y[:,i])\n",
    "            self.fit_models.append(m_i)\n",
    "\n",
    "    def predict(self, x_ex):\n",
    "        '''\n",
    "        Predict the classification for all provided examples\n",
    "        :param x_ex: features vectors with example instances\n",
    "        :return:\n",
    "        '''\n",
    "        out = []\n",
    "        for i in range(len(x_ex)):\n",
    "            classes = []\n",
    "            for j in range(len(self.fit_models)):\n",
    "                classes.append(self.fit_models[j].predict([x_ex[i]]))\n",
    "            out.append(classes)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def feature_accuracy(self, x_ex, y_known):\n",
    "        '''\n",
    "        Custom function to generate accuracy, precision, and recall results for overall\n",
    "        and each class label.\n",
    "        :param x_ex: examples of feature vector to be predicted\n",
    "        :param y_known: known values of labels for each example\n",
    "        :return: a dictionary with metric values for each class\n",
    "        '''\n",
    "        feats = {}\n",
    "        t, f_p, f_n, t_n, t_p = 0, 0,0,0,0\n",
    "\n",
    "        for f in range(len(self.fit_models)):\n",
    "            true = y_known[:, f]\n",
    "            pred = self.fit_models[f].predict(x_ex)\n",
    "\n",
    "            true_pos, false_pos, false_neg,true_neg  = 0,0,0,0\n",
    "            total = 0\n",
    "\n",
    "            for i in range(len(pred)):\n",
    "                total += 1\n",
    "                if pred[i] == 1 and true[i] == 1:\n",
    "                    true_pos += 1\n",
    "                elif pred[i] == 1 and true[i] == 0:\n",
    "                    false_pos += 1\n",
    "                elif pred[i] == 0 and true[i] == 1:\n",
    "                    false_neg += 1\n",
    "                elif pred[i] == 0 and true[i] == 0:\n",
    "                    true_neg += 1\n",
    "                else:\n",
    "                    raise Exception(\"Unknwon label encountered\")\n",
    "\n",
    "            t += total\n",
    "            t_n += true_neg\n",
    "            t_p += true_pos\n",
    "            f_n += false_neg\n",
    "            f_p += false_pos\n",
    "\n",
    "            feats[f] = total, true_neg, true_pos, false_neg, false_pos\n",
    "\n",
    "        print(\"Accuracy: \", (t_p + t_n)/t)\n",
    "        print(\"Precision: \", t_p / (t_p + f_p))\n",
    "        print(\"Recall: \", t_p / (t_p + f_n))\n",
    "\n",
    "        return feats\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load in data for features and labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = np.load(\"data/tp_source_trimmed.npy\", allow_pickle=True)\n",
    "moods = np.load(\"data/moods_target_trimmed.npy\", allow_pickle=True)[:, 1]\n",
    "m_len = len(moods[0])\n",
    "\n",
    "features = preprocessing.normalize(features)\n",
    "\n",
    "moods = np.stack(moods)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create basic 80/20 random split for testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, moods, test_size=0.2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run classifier on Decision Tree:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_dc = MultiLabelClassify(model='DC')\n",
    "multi_dc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report stats and save individual label results for analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = multi_dc.feature_accuracy(X_test, y_test)\n",
    "\n",
    "with open(\"dc_results.json\", \"w\") as outfile:\n",
    "    json.dump(stats, outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run classifier on Random Forest:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_dc = MultiLabelClassify(model='RF')\n",
    "multi_dc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report stats and save individual label results for analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = multi_dc.feature_accuracy(X_test, y_test)\n",
    "\n",
    "with open(\"rf_results.json\", \"w\") as outfile:\n",
    "    json.dump(stats, outfile)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 2: Results Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load in data from results and mood labels for reporting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = \"data/listening_moods_data/moods.txt\"\n",
    "l = []\n",
    "\n",
    "f = open(labels, \"r\")\n",
    "for x in f:\n",
    "    l.append(str.strip(x))\n",
    "\n",
    "rf = \"results/rf_results.json\"\n",
    "dc = \"results/dc_results.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function for reuse to analyze both results files:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def results_analysis(file_name, l):\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        results = json.load(json_file)\n",
    "\n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    zero_index = []\n",
    "\n",
    "    for i in results.keys():\n",
    "        accuracy.append((results[i][1] + results[i][2]) / results[i][0])\n",
    "\n",
    "        if results[i][2] != 0:\n",
    "            zero_index.append(int(i))\n",
    "            precision.append(results[i][2] / (results[i][2] + results[i][4]))\n",
    "            recall.append(results[i][2] / (results[i][2] + results[i][3]))\n",
    "\n",
    "    print(max(accuracy), l[np.argmin(accuracy)])\n",
    "    print(min(accuracy), l[np.argmax(accuracy)])\n",
    "    print(np.mean(accuracy), '\\n')\n",
    "\n",
    "    print(max(precision), l[np.argmin(precision)])\n",
    "    print(min(precision), l[np.argmax(precision)])\n",
    "    print(np.mean(precision), '\\n')\n",
    "\n",
    "    print(max(recall), l[np.argmin(recall)])\n",
    "    print(min(recall), l[np.argmax(recall)])\n",
    "    print(np.mean(recall), '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report on Decision Tree results:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_analysis(dc, l)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report on Random Forest results:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_analysis(rf, l)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}