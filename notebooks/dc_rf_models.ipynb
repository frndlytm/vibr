{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Decision Tree and Random Forests for Mood Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create class to run binary classification using either model on each of the moods in\n",
    "the label set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class MultiLabelClassify:\n",
    "    '''\n",
    "    Multilabel Classifier for fitting binary classification to each label.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, model):\n",
    "        '''\n",
    "        Set up an instance of the classifier.\n",
    "        :param model: Choice of 'RF' for random forest or 'DC' for decision tree\n",
    "        '''\n",
    "        self.fit_models = None\n",
    "        if model != 'RF' and model != 'DC':\n",
    "            raise Exception('Choose RF or DC as model type')\n",
    "        self.model_choice = model\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Fit model with provided features and labels\n",
    "        :param X: features vector\n",
    "        :param y: matching labels, where length of each vector contains all label classifications\n",
    "        for the given features vector\n",
    "        '''\n",
    "        classes = len(y[0])\n",
    "        self.fit_models = []\n",
    "\n",
    "        if len(X) != len(y):\n",
    "            raise Exception(\"Incompatible featues and label lengths\")\n",
    "\n",
    "        for i in range(classes):\n",
    "            if self.model_choice == 'RF':\n",
    "                m_i = RandomForestClassifier(max_features='sqrt', bootstrap=True, n_estimators=100)\n",
    "            else:\n",
    "                m_i = DecisionTreeClassifier()\n",
    "            m_i.fit(X,  y[:,i])\n",
    "            self.fit_models.append(m_i)\n",
    "\n",
    "    def predict(self, x_ex):\n",
    "        '''\n",
    "        Predict the classification for all provided examples\n",
    "        :param x_ex: features vectors with example instances\n",
    "        :return:\n",
    "        '''\n",
    "        out = []\n",
    "        for i in range(len(x_ex)):\n",
    "            classes = []\n",
    "            for j in range(len(self.fit_models)):\n",
    "                classes.append(self.fit_models[j].predict([x_ex[i]]))\n",
    "            out.append(classes)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def feature_accuracy(self, x_ex, y_known):\n",
    "        '''\n",
    "        Custom function to generate accuracy, precision, and recall results for overall\n",
    "        and each class label.\n",
    "        :param x_ex: examples of feature vector to be predicted\n",
    "        :param y_known: known values of labels for each example\n",
    "        :return: a dictionary with metric values for each class\n",
    "        '''\n",
    "        feats = {}\n",
    "        t, f_p, f_n, t_n, t_p = 0, 0,0,0,0\n",
    "\n",
    "        for f in range(len(self.fit_models)):\n",
    "            true = y_known[:, f]\n",
    "            pred = self.fit_models[f].predict(x_ex)\n",
    "\n",
    "            true_pos, false_pos, false_neg,true_neg  = 0,0,0,0\n",
    "            total = 0\n",
    "\n",
    "            for i in range(len(pred)):\n",
    "                total += 1\n",
    "                if pred[i] == 1 and true[i] == 1:\n",
    "                    true_pos += 1\n",
    "                elif pred[i] == 1 and true[i] == 0:\n",
    "                    false_pos += 1\n",
    "                elif pred[i] == 0 and true[i] == 1:\n",
    "                    false_neg += 1\n",
    "                elif pred[i] == 0 and true[i] == 0:\n",
    "                    true_neg += 1\n",
    "                else:\n",
    "                    raise Exception(\"Unknwon label encountered\")\n",
    "\n",
    "            t += total\n",
    "            t_n += true_neg\n",
    "            t_p += true_pos\n",
    "            f_n += false_neg\n",
    "            f_p += false_pos\n",
    "\n",
    "            feats[f] = total, true_neg, true_pos, false_neg, false_pos\n",
    "\n",
    "        print(\"Accuracy: \", (t_p + t_n)/t)\n",
    "        print(\"Precision: \", t_p / (t_p + f_p))\n",
    "        print(\"Recall: \", t_p / (t_p + f_n))\n",
    "\n",
    "        return feats\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load in data for features and labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "features = np.load(\"../data/tp_source_trimmed.npy\", allow_pickle=True)\n",
    "moods = np.load(\"../data/moods_target_trimmed.npy\", allow_pickle=True)[:, 1]\n",
    "m_len = len(moods[0])\n",
    "\n",
    "features = preprocessing.normalize(features)\n",
    "\n",
    "moods = np.stack(moods)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create basic 80/20 random split for testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, moods, test_size=0.2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run classifier on Decision Tree:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m multi_dc \u001B[38;5;241m=\u001B[39m MultiLabelClassify(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDC\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmulti_dc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36mMultiLabelClassify.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     34\u001B[0m     m_i \u001B[38;5;241m=\u001B[39m DecisionTreeClassifier()\n\u001B[1;32m---> 35\u001B[0m \u001B[43mm_i\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43my\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_models\u001B[38;5;241m.\u001B[39mappend(m_i)\n",
      "File \u001B[1;32mc:\\users\\aebis\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001B[0m, in \u001B[0;36mDecisionTreeClassifier.fit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    899\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\n\u001B[0;32m    900\u001B[0m     \u001B[38;5;28mself\u001B[39m, X, y, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, check_input\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, X_idx_sorted\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdeprecated\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    901\u001B[0m ):\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001B[39;00m\n\u001B[0;32m    903\u001B[0m \n\u001B[0;32m    904\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    934\u001B[0m \u001B[38;5;124;03m        Fitted estimator.\u001B[39;00m\n\u001B[0;32m    935\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 937\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    938\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    939\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    940\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    941\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_input\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    942\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_idx_sorted\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_idx_sorted\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    943\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    944\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32mc:\\users\\aebis\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001B[0m, in \u001B[0;36mBaseDecisionTree.fit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    409\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    410\u001B[0m     builder \u001B[38;5;241m=\u001B[39m BestFirstTreeBuilder(\n\u001B[0;32m    411\u001B[0m         splitter,\n\u001B[0;32m    412\u001B[0m         min_samples_split,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    417\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_impurity_decrease,\n\u001B[0;32m    418\u001B[0m     )\n\u001B[1;32m--> 420\u001B[0m \u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtree_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_outputs_ \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_classifier(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    423\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "multi_dc = MultiLabelClassify(model='DC')\n",
    "multi_dc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report stats and save individual label results for analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = multi_dc.feature_accuracy(X_test, y_test)\n",
    "\n",
    "with open(\"../results/dc_results.json\", \"w\") as outfile:\n",
    "    json.dump(stats, outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run classifier on Random Forest:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "multi_dc = MultiLabelClassify(model='RF')\n",
    "multi_dc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report stats and save individual label results for analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stats = multi_dc.feature_accuracy(X_test, y_test)\n",
    "\n",
    "with open(\"../results/rf_results.json\", \"w\") as outfile:\n",
    "    json.dump(stats, outfile)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Part 2: Results Analysis"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load in data from results and mood labels for reporting."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "labels = \"../data/moods.txt\"\n",
    "l = []\n",
    "\n",
    "f = open(labels, \"r\")\n",
    "for x in f:\n",
    "    l.append(str.strip(x))\n",
    "\n",
    "rf = \"../results/rf_results.json\"\n",
    "dc = \"../results/dc_results.json\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define a function for reuse to analyze both results files:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def results_analysis(file_name, l):\n",
    "    with open(file_name, \"r\") as json_file:\n",
    "        results = json.load(json_file)\n",
    "\n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    zero_index = []\n",
    "\n",
    "    for i in results.keys():\n",
    "        accuracy.append((results[i][1] + results[i][2]) / results[i][0])\n",
    "\n",
    "        if results[i][2] != 0:\n",
    "            zero_index.append(int(i))\n",
    "            precision.append(results[i][2] / (results[i][2] + results[i][4]))\n",
    "            recall.append(results[i][2] / (results[i][2] + results[i][3]))\n",
    "\n",
    "    print(max(accuracy), l[np.argmin(accuracy)])\n",
    "    print(min(accuracy), l[np.argmax(accuracy)])\n",
    "    print(np.mean(accuracy), '\\n')\n",
    "\n",
    "    print(max(precision), l[np.argmin(precision)])\n",
    "    print(min(precision), l[np.argmax(precision)])\n",
    "    print(np.mean(precision), '\\n')\n",
    "\n",
    "    print(max(recall), l[np.argmin(recall)])\n",
    "    print(min(recall), l[np.argmax(recall)])\n",
    "    print(np.mean(recall), '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report on Decision Tree results:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_analysis(dc, l)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report on Random Forest results:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_analysis(rf, l)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}